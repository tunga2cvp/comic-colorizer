{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"DsNStKpihksD"},"outputs":[],"source":["# This section is to move to the directory on Google Drive\n","import os\n","# os.chdir('drive/MyDrive/ComVis_20211')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lhtY5474hrBp"},"outputs":[],"source":["import numpy as np # linear algebra\n","import os\n","import cv2\n","from keras import backend as K\n","from keras.layers import Conv2D,UpSampling2D,Input\n","from keras.layers.merge import concatenate\n","from keras.models import Model\n","from keras.preprocessing.image import img_to_array, load_img\n","import tensorflow as tf\n","from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n","from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n","from skimage.transform import resize\n","import math\n","\n","tf.random.set_seed(123)\n","session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","tf.compat.v1.keras.backend.set_session(sess)\n","tf.random.set_seed(2)\n","np.random.seed(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zxq7kt2bhrET"},"outputs":[],"source":["HEIGHT=256\n","WIDTH=256\n","\n","trainPath = 'Train'\n","validPath = 'Valid'\n","testPath = 'Test'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6c0T8LpxhrG9"},"outputs":[],"source":["# backbone from pretrained model\n","def create_resnet_embedding(grayscaled_rgb):\n","    grayscaled_rgb_resized = []\n","    for i in grayscaled_rgb:\n","        i = resize(i, (224, 224, 3), mode='constant')\n","        grayscaled_rgb_resized.append(i)\n","    grayscaled_rgb_resized = np.array(grayscaled_rgb_resized)\n","    grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n","    embed = resnet.predict(grayscaled_rgb_resized)\n","    return embed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vuLRH8UshrJm"},"outputs":[],"source":["# extract color\n","def color_extraction(rgb_batch, HEIGHT, WIDTH):\n","    color_r = []\n","    color_g = []\n","    color_b = []\n","    for img in rgb_batch:\n","        r = cv2.calcHist([img], [0], mask=None, histSize=[256], ranges=[0,1])\n","        g = cv2.calcHist([img], [1], mask=None, histSize=[256], ranges=[0,1])\n","        b = cv2.calcHist([img], [2], mask=None, histSize=[256], ranges=[0,1])\n","        r = r[:, 0]/(HEIGHT*WIDTH)\n","        g = g[:, 0]/(HEIGHT*WIDTH)\n","        b = b[:, 0]/(HEIGHT*WIDTH)\n","        color_r.append(r)\n","        color_g.append(g)\n","        color_b.append(b)\n","    color_r = np.array(color_r)\n","    color_g = np.array(color_g)\n","    color_b = np.array(color_b)\n","    \n","    return color_r, color_g, color_b"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QIUrbaivhrMC"},"outputs":[],"source":["class DataSequence(tf.keras.utils.Sequence):\n","\n","  def __init__(self, imagePath, batch_size):\n","      self.imagePath = imagePath\n","      self.img_list = os.listdir(imagePath)\n","      self.batch_size = batch_size\n","      \n","\n","  def __len__(self):\n","      return math.ceil(len(self.img_list) / self.batch_size)\n","\n","  def __getitem__(self, idx):\n","      X = []\n","      for image in self.img_list[( idx*self.batch_size ) : ( (idx+1) * self.batch_size )]:\n","          img = img_to_array(load_img(os.path.join(self.imagePath, image)))\n","          img = resize(img, (HEIGHT,WIDTH,3))\n","          X.append(img)\n","      X = np.array(X, dtype=np.float32)\n","      Xtrain = 1.0/255*X\n","\n","      grayscaled_rgb = gray2rgb(rgb2gray(Xtrain))\n","      embed = create_resnet_embedding(grayscaled_rgb)\n","      color_r, color_g, color_b = color_extraction(Xtrain, HEIGHT, WIDTH)\n","      X_batch = grayscaled_rgb[:,:,:,0]\n","      X_batch = X_batch.reshape(X_batch.shape+(1,))\n","      Y_batch = Xtrain\n","\n","      return ([X_batch, embed, color_r, color_g, color_b], Y_batch)\n","    #   return ([X_batch, embed], Y_batch)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2931,"status":"ok","timestamp":1640534699514,"user":{"displayName":"Tuom Tat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06057362015267760681"},"user_tz":-420},"id":"MowbK2EnhrOl","outputId":"16485e6b-a7b2-4172-fde3-cd196c71a1f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n","102973440/102967424 [==============================] - 1s 0us/step\n","102981632/102967424 [==============================] - 1s 0us/step\n"]}],"source":["K.clear_session()\n","#Load weights\n","resnet = tf.keras.applications.resnet50.ResNet50(include_top=True, weights='imagenet', classes=1000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JjdLfsrvh0pz"},"outputs":[],"source":["CHECKPOINT = 'models/unet_color_rgb'\n","if not os.path.exists(CHECKPOINT):\n","    embed_input = Input(shape=(1000,))\n","    color_r_input = Input(shape=(256,)) #channel r color\n","    color_g_input = Input(shape=(256,)) #channel g color\n","    color_b_input = Input(shape=(256,)) #channel b color\n","\n","    #Encoder\n","    encoder_input = Input(shape=(256, 256, 1,))\n","    encoder_256 = Conv2D(64, (3,3), activation='relu', padding='same')(encoder_input)\n","    encoder_128 = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(encoder_256)\n","    encoder_128 = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_128)\n","    encoder_64 = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_128)\n","    encoder_64 = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_64)\n","    encoder_32 = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_64)\n","    encoder_32 = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_32)\n","    encoder_32 = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_32)\n","    encoder_32 = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_32)\n","\n","    #Fusion\n","    fusion_r = tf.keras.layers.RepeatVector(32 * 32)(color_r_input)\n","    fusion_r = tf.keras.layers.Reshape(([32, 32, 256]))(fusion_r)\n","    fusion_g = tf.keras.layers.RepeatVector(32 * 32)(color_g_input)\n","    fusion_g = tf.keras.layers.Reshape(([32, 32, 256]))(fusion_g)\n","    fusion_b = tf.keras.layers.RepeatVector(32 * 32)(color_b_input)\n","    fusion_b = tf.keras.layers.Reshape(([32, 32, 256]))(fusion_b)\n","    fusion_output = tf.keras.layers.RepeatVector(32 * 32)(embed_input)\n","    fusion_output = tf.keras.layers.Reshape(([32, 32, 1000]))(fusion_output)\n","    fusion_output = concatenate([fusion_output, fusion_r, fusion_g, fusion_b], axis=3) \n","    fusion_output = Conv2D(256, (1, 1), activation='relu', padding='same')(fusion_output) \n","\n","    #Decoder\n","    decoder_32 = concatenate([encoder_32, fusion_output], axis=3)\n","    decoder_32 = Conv2D(256, (3,3), activation='relu', padding='same')(decoder_32)\n","    # decoder_32 = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_32)\n","    decoder_64 = UpSampling2D((2, 2))(decoder_32)\n","    decoder_64 = concatenate([encoder_64, decoder_64], axis=3)\n","    decoder_64 = Conv2D(256, (3,3), activation='relu', padding='same')(decoder_64)\n","    decoder_64 = Conv2D(128, (3,3), activation='relu', padding='same')(decoder_64)\n","    decoder_128 = UpSampling2D((2, 2))(decoder_64)\n","    decoder_128 = concatenate([encoder_128, decoder_128], axis=3)\n","    decoder_128 = Conv2D(128, (3,3), activation='relu', padding='same')(decoder_128)\n","    decoder_128 = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_128)\n","    decoder_256 = UpSampling2D((2, 2))(decoder_128)\n","    decoder_256 = concatenate([encoder_256, decoder_256], axis=3)\n","    decoder_256 = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_256)\n","    decoder_output = Conv2D(3, (3,3), activation='tanh', padding='same')(decoder_256)\n","    \n","\n","    model = Model(inputs=[encoder_input, embed_input, color_r_input, color_g_input, color_b_input], outputs=decoder_output)\n","    # model = Model(inputs=[encoder_input, embed_input], outputs=decoder_output)\n","else:\n","    model = tf.keras.models.load_model(CHECKPOINT)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1640534710754,"user":{"displayName":"Tuom Tat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06057362015267760681"},"user_tz":-420},"id":"G-yN6BV6h0uN","outputId":"5521eed0-9a59-4f29-a661-3a3601724c6c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_6 (InputLayer)           [(None, 256, 256, 1  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 256, 256, 64  640         ['input_6[0][0]']                \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 128, 128, 64  36928       ['conv2d[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 128, 128, 12  73856       ['conv2d_1[0][0]']               \n","                                8)                                                                \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 64, 64, 128)  147584      ['conv2d_2[0][0]']               \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 64, 64, 256)  295168      ['conv2d_3[0][0]']               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 1000)]       0           []                               \n","                                                                                                  \n"," input_3 (InputLayer)           [(None, 256)]        0           []                               \n","                                                                                                  \n"," input_4 (InputLayer)           [(None, 256)]        0           []                               \n","                                                                                                  \n"," input_5 (InputLayer)           [(None, 256)]        0           []                               \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 32, 32, 256)  590080      ['conv2d_4[0][0]']               \n","                                                                                                  \n"," repeat_vector_3 (RepeatVector)  (None, 1024, 1000)  0           ['input_2[0][0]']                \n","                                                                                                  \n"," repeat_vector (RepeatVector)   (None, 1024, 256)    0           ['input_3[0][0]']                \n","                                                                                                  \n"," repeat_vector_1 (RepeatVector)  (None, 1024, 256)   0           ['input_4[0][0]']                \n","                                                                                                  \n"," repeat_vector_2 (RepeatVector)  (None, 1024, 256)   0           ['input_5[0][0]']                \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 32, 32, 512)  1180160     ['conv2d_5[0][0]']               \n","                                                                                                  \n"," reshape_3 (Reshape)            (None, 32, 32, 1000  0           ['repeat_vector_3[0][0]']        \n","                                )                                                                 \n","                                                                                                  \n"," reshape (Reshape)              (None, 32, 32, 256)  0           ['repeat_vector[0][0]']          \n","                                                                                                  \n"," reshape_1 (Reshape)            (None, 32, 32, 256)  0           ['repeat_vector_1[0][0]']        \n","                                                                                                  \n"," reshape_2 (Reshape)            (None, 32, 32, 256)  0           ['repeat_vector_2[0][0]']        \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 32, 32, 512)  2359808     ['conv2d_6[0][0]']               \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 32, 32, 1768  0           ['reshape_3[0][0]',              \n","                                )                                 'reshape[0][0]',                \n","                                                                  'reshape_1[0][0]',              \n","                                                                  'reshape_2[0][0]']              \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 32, 32, 256)  1179904     ['conv2d_7[0][0]']               \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, 32, 32, 256)  452864      ['concatenate[0][0]']            \n","                                                                                                  \n"," concatenate_1 (Concatenate)    (None, 32, 32, 512)  0           ['conv2d_8[0][0]',               \n","                                                                  'conv2d_9[0][0]']               \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, 32, 32, 256)  1179904     ['concatenate_1[0][0]']          \n","                                                                                                  \n"," up_sampling2d (UpSampling2D)   (None, 64, 64, 256)  0           ['conv2d_10[0][0]']              \n","                                                                                                  \n"," concatenate_2 (Concatenate)    (None, 64, 64, 512)  0           ['conv2d_4[0][0]',               \n","                                                                  'up_sampling2d[0][0]']          \n","                                                                                                  \n"," conv2d_11 (Conv2D)             (None, 64, 64, 256)  1179904     ['concatenate_2[0][0]']          \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 64, 64, 128)  295040      ['conv2d_11[0][0]']              \n","                                                                                                  \n"," up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 12  0          ['conv2d_12[0][0]']              \n","                                8)                                                                \n","                                                                                                  \n"," concatenate_3 (Concatenate)    (None, 128, 128, 25  0           ['conv2d_2[0][0]',               \n","                                6)                                'up_sampling2d_1[0][0]']        \n","                                                                                                  \n"," conv2d_13 (Conv2D)             (None, 128, 128, 12  295040      ['concatenate_3[0][0]']          \n","                                8)                                                                \n","                                                                                                  \n"," conv2d_14 (Conv2D)             (None, 128, 128, 64  73792       ['conv2d_13[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 64  0          ['conv2d_14[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," concatenate_4 (Concatenate)    (None, 256, 256, 12  0           ['conv2d[0][0]',                 \n","                                8)                                'up_sampling2d_2[0][0]']        \n","                                                                                                  \n"," conv2d_15 (Conv2D)             (None, 256, 256, 64  73792       ['concatenate_4[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_16 (Conv2D)             (None, 256, 256, 3)  1731        ['conv2d_15[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 9,416,195\n","Trainable params: 9,416,195\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["LEARNING_RATE = 0.0005\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n","                            loss='mean_absolute_error')\n","BATCH_SIZE = 32\n","EPOCHS = 50\n","\n","early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, \n","                           mode='auto', restore_best_weights=True)\n","\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n","                                filepath=CHECKPOINT,\n","                                save_weights_only=False,\n","                                monitor='val_loss',\n","                                mode='max',\n","                                save_best_only=False)\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"My2a6l_Ih8XT","outputId":"0f2f7bbb-6715-426e-ee79-8d2fa6f7b9ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0105INFO:tensorflow:Assets written to: model_unet_resnet_rgb_color_experimental/assets\n","216/216 [==============================] - 1407s 6s/step - loss: 0.0105 - val_loss: 0.0174\n","Epoch 2/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0097INFO:tensorflow:Assets written to: model_unet_resnet_rgb_color_experimental/assets\n","216/216 [==============================] - 661s 3s/step - loss: 0.0097 - val_loss: 0.0174\n","Epoch 3/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0099INFO:tensorflow:Assets written to: model_unet_resnet_rgb_color_experimental/assets\n","216/216 [==============================] - 669s 3s/step - loss: 0.0099 - val_loss: 0.0177\n","Epoch 4/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0098INFO:tensorflow:Assets written to: model_unet_resnet_rgb_color_experimental/assets\n","216/216 [==============================] - 678s 3s/step - loss: 0.0098 - val_loss: 0.0186\n","Epoch 5/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0097INFO:tensorflow:Assets written to: model_unet_resnet_rgb_color_experimental/assets\n","216/216 [==============================] - 687s 3s/step - loss: 0.0097 - val_loss: 0.0175\n","Epoch 6/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0098INFO:tensorflow:Assets written to: model_unet_resnet_rgb_color_experimental/assets\n","216/216 [==============================] - 677s 3s/step - loss: 0.0098 - val_loss: 0.0180\n","Epoch 7/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0101INFO:tensorflow:Assets written to: model_unet_resnet_rgb_color_experimental/assets\n","216/216 [==============================] - 668s 3s/step - loss: 0.0101 - val_loss: 0.0174\n","Epoch 8/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0096INFO:tensorflow:Assets written to: model_unet_resnet_rgb_color_experimental/assets\n","216/216 [==============================] - 663s 3s/step - loss: 0.0096 - val_loss: 0.0176\n","Epoch 9/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0094INFO:tensorflow:Assets written to: model_unet_resnet_rgb_color_experimental/assets\n","216/216 [==============================] - 660s 3s/step - loss: 0.0094 - val_loss: 0.0184\n","Epoch 10/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0099INFO:tensorflow:Assets written to: model_unet_resnet_rgb_color_experimental/assets\n","216/216 [==============================] - 658s 3s/step - loss: 0.0099 - val_loss: 0.0173\n","Epoch 11/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0094INFO:tensorflow:Assets written to: model_unet_resnet_rgb_color_experimental/assets\n","216/216 [==============================] - 659s 3s/step - loss: 0.0094 - val_loss: 0.0173\n","Epoch 12/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0093INFO:tensorflow:Assets written to: model_unet_resnet_rgb_color_experimental/assets\n","216/216 [==============================] - 662s 3s/step - loss: 0.0093 - val_loss: 0.0174\n","Epoch 13/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0094INFO:tensorflow:Assets written to: model_unet_resnet_rgb_color_experimental/assets\n","216/216 [==============================] - 661s 3s/step - loss: 0.0094 - val_loss: 0.0173\n","Epoch 14/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0096INFO:tensorflow:Assets written to: model_unet_resnet_rgb_color_experimental/assets\n","216/216 [==============================] - 664s 3s/step - loss: 0.0096 - val_loss: 0.0180\n","Epoch 15/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0096INFO:tensorflow:Assets written to: model_unet_resnet_rgb_color_experimental/assets\n","216/216 [==============================] - 660s 3s/step - loss: 0.0096 - val_loss: 0.0175\n","Epoch 16/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0092INFO:tensorflow:Assets written to: model_unet_resnet_rgb_color_experimental/assets\n","216/216 [==============================] - 664s 3s/step - loss: 0.0092 - val_loss: 0.0177\n","Epoch 17/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0090INFO:tensorflow:Assets written to: model_unet_resnet_rgb_color_experimental/assets\n","216/216 [==============================] - 657s 3s/step - loss: 0.0090 - val_loss: 0.0177\n","Epoch 18/50\n","193/216 [=========================>....] - ETA: 1:00 - loss: 0.0097"]}],"source":["model.fit(DataSequence(trainPath,BATCH_SIZE),\n","                        batch_size=BATCH_SIZE,\n","                        epochs=EPOCHS,\n","                        validation_data=DataSequence(validPath,BATCH_SIZE),\n","                        shuffle=True,\n","                        callbacks=[early_stop, model_checkpoint])"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPLWvUeJ9aGYzqPORxitZOh","collapsed_sections":[],"mount_file_id":"1LgnIDDCJHdgoQaDC_9G-ShPpIzHHxnmO","name":"model_unet_rgb.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
