{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":316,"status":"ok","timestamp":1639055014583,"user":{"displayName":"Tuom Tat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06057362015267760681"},"user_tz":-420},"id":"tnsSfkyTVPGe"},"outputs":[],"source":["# This section is to move to the directory on Google Drive\n","import os\n","# os.chdir('drive/MyDrive/ComVis_20211')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":7507,"status":"ok","timestamp":1639055022516,"user":{"displayName":"Tuom Tat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06057362015267760681"},"user_tz":-420},"id":"E-VG8RquVWUs"},"outputs":[],"source":["import numpy as np # linear algebra\n","import os\n","import cv2\n","from keras import backend as K\n","from keras.layers import Conv2D,UpSampling2D,Input\n","from keras.layers.merge import concatenate\n","from keras.models import Model\n","from keras.preprocessing.image import img_to_array, load_img\n","import tensorflow as tf\n","from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n","from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n","from skimage.transform import resize\n","import math\n","\n","tf.random.set_seed(123)\n","session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","tf.compat.v1.keras.backend.set_session(sess)\n","tf.random.set_seed(2)\n","np.random.seed(1)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1639055022518,"user":{"displayName":"Tuom Tat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06057362015267760681"},"user_tz":-420},"id":"f_vaqjH6VYgj"},"outputs":[],"source":["HEIGHT=256\n","WIDTH=256\n","\n","trainPath = 'Train'\n","validPath = 'Valid'\n","testPath = 'Test'"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1639055022519,"user":{"displayName":"Tuom Tat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06057362015267760681"},"user_tz":-420},"id":"fyeG2CdPVZt7"},"outputs":[],"source":["# backbone from pretrained model\n","def create_resnet_embedding(grayscaled_rgb):\n","    grayscaled_rgb_resized = []\n","    for i in grayscaled_rgb:\n","        i = resize(i, (224, 224, 3), mode='constant')\n","        grayscaled_rgb_resized.append(i)\n","    grayscaled_rgb_resized = np.array(grayscaled_rgb_resized)\n","    grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n","    embed = resnet.predict(grayscaled_rgb_resized)\n","    return embed"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1639055022520,"user":{"displayName":"Tuom Tat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06057362015267760681"},"user_tz":-420},"id":"LHHZfl5yVa6L"},"outputs":[],"source":["# extract color\n","def color_extraction(lab_batch, HEIGHT, WIDTH):\n","    color_a = []\n","    color_b = []\n","    for img in lab_batch:\n","        a = cv2.calcHist([img], [1], mask=None, histSize=[256], ranges=[-128, 128])\n","        b = cv2.calcHist([img], [2], mask=None, histSize=[256], ranges=[-128, 128])\n","        a = a[:, 0]/(HEIGHT*WIDTH)\n","        b = b[:, 0]/(HEIGHT*WIDTH)\n","        color_a.append(a)\n","        color_b.append(b)\n","    color_a = np.array(color_a)\n","    color_b = np.array(color_b)\n","    \n","    return color_a, color_b"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1639055022528,"user":{"displayName":"Tuom Tat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06057362015267760681"},"user_tz":-420},"id":"kcMYsSu1VcJs"},"outputs":[],"source":["class DataSequence(tf.keras.utils.Sequence):\n","\n","  def __init__(self, imagePath, batch_size):\n","      self.imagePath = imagePath\n","      self.img_list = os.listdir(imagePath)\n","      self.batch_size = batch_size\n","      \n","\n","  def __len__(self):\n","      return math.ceil(len(self.img_list) / self.batch_size)\n","\n","  def __getitem__(self, idx):\n","      X = []\n","      for image in self.img_list[( idx*self.batch_size ) : ( (idx+1) * self.batch_size )]:\n","          img = img_to_array(load_img(os.path.join(self.imagePath, image)))\n","          img = resize(img, (HEIGHT,WIDTH,3))\n","          X.append(img)\n","      X = np.array(X, dtype=np.float32)\n","      Xtrain = 1.0/255*X\n","\n","      grayscaled_rgb = gray2rgb(rgb2gray(Xtrain))\n","      embed = create_resnet_embedding(grayscaled_rgb)\n","      lab_batch = rgb2lab(Xtrain)\n","      color_a, color_b = color_extraction(lab_batch, HEIGHT, WIDTH)\n","      X_batch = lab_batch[:,:,:,0]\n","      X_batch = X_batch.reshape(X_batch.shape+(1,))\n","      Y_batch = lab_batch[:,:,:,1:] / 128\n","\n","      return ([X_batch, embed, color_a, color_b], Y_batch)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3299,"status":"ok","timestamp":1639055025807,"user":{"displayName":"Tuom Tat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06057362015267760681"},"user_tz":-420},"id":"jF3yY0J0Vddz","outputId":"fbdc6713-79d0-4c61-a54e-89a871c793bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n","102973440/102967424 [==============================] - 1s 0us/step\n","102981632/102967424 [==============================] - 1s 0us/step\n"]}],"source":["K.clear_session()\n","#Load weights\n","resnet = tf.keras.applications.resnet50.ResNet50(include_top=True, weights='imagenet', classes=1000)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":6293,"status":"ok","timestamp":1639055032083,"user":{"displayName":"Tuom Tat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06057362015267760681"},"user_tz":-420},"id":"MxnmByIMVeiK"},"outputs":[],"source":["CHECKPOINT = 'models/encoder_color_lab'\n","if not os.path.exists(CHECKPOINT):\n","    embed_input = Input(shape=(1000,))\n","    color_a_input = Input(shape=(256,)) #channel a color\n","    color_b_input = Input(shape=(256,)) #channel b color\n","\n","    #Encoder\n","    encoder_input = Input(shape=(256, 256, 1,))\n","    encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(encoder_input)\n","    encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n","    encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n","    encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n","    encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n","    encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n","    encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n","    encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n","\n","    #Fusion\n","    fusion_a = tf.keras.layers.RepeatVector(32 * 32)(color_a_input)\n","    fusion_a = tf.keras.layers.Reshape(([32, 32, 256]))(fusion_a)\n","    fusion_b = tf.keras.layers.RepeatVector(32 * 32)(color_b_input)\n","    fusion_b = tf.keras.layers.Reshape(([32, 32, 256]))(fusion_b)\n","    fusion_output = tf.keras.layers.RepeatVector(32 * 32)(embed_input)\n","    fusion_output = tf.keras.layers.Reshape(([32, 32, 1000]))(fusion_output)\n","    fusion_output = concatenate([encoder_output, fusion_output, fusion_a, fusion_b], axis=3) \n","    fusion_output = Conv2D(256, (1, 1), activation='relu', padding='same')(fusion_output) \n","\n","    #Decoder\n","    decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(fusion_output)\n","    decoder_output = UpSampling2D((2, 2))(decoder_output)\n","    decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n","    decoder_output = UpSampling2D((2, 2))(decoder_output)\n","    decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n","    decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n","    decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n","    decoder_output = UpSampling2D((2, 2))(decoder_output)\n","\n","    model = Model(inputs=[encoder_input, embed_input, color_a_input, color_b_input], outputs=decoder_output)\n","else:\n","    model = tf.keras.models.load_model(CHECKPOINT)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1639055032084,"user":{"displayName":"Tuom Tat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06057362015267760681"},"user_tz":-420},"id":"kwqKUljlVf67","outputId":"7801b8cc-e2f9-4e4f-d77e-9ec2ef7a42f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_5 (InputLayer)           [(None, 256, 256, 1  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 128, 128, 64  640         ['input_5[0][0]']                \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 128, 128, 12  73856       ['conv2d[0][0]']                 \n","                                8)                                                                \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 64, 64, 128)  147584      ['conv2d_1[0][0]']               \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 64, 64, 256)  295168      ['conv2d_2[0][0]']               \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 32, 32, 256)  590080      ['conv2d_3[0][0]']               \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 32, 32, 512)  1180160     ['conv2d_4[0][0]']               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 1000)]       0           []                               \n","                                                                                                  \n"," input_3 (InputLayer)           [(None, 256)]        0           []                               \n","                                                                                                  \n"," input_4 (InputLayer)           [(None, 256)]        0           []                               \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 32, 32, 512)  2359808     ['conv2d_5[0][0]']               \n","                                                                                                  \n"," repeat_vector_2 (RepeatVector)  (None, 1024, 1000)  0           ['input_2[0][0]']                \n","                                                                                                  \n"," repeat_vector (RepeatVector)   (None, 1024, 256)    0           ['input_3[0][0]']                \n","                                                                                                  \n"," repeat_vector_1 (RepeatVector)  (None, 1024, 256)   0           ['input_4[0][0]']                \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 32, 32, 256)  1179904     ['conv2d_6[0][0]']               \n","                                                                                                  \n"," reshape_2 (Reshape)            (None, 32, 32, 1000  0           ['repeat_vector_2[0][0]']        \n","                                )                                                                 \n","                                                                                                  \n"," reshape (Reshape)              (None, 32, 32, 256)  0           ['repeat_vector[0][0]']          \n","                                                                                                  \n"," reshape_1 (Reshape)            (None, 32, 32, 256)  0           ['repeat_vector_1[0][0]']        \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 32, 32, 1768  0           ['conv2d_7[0][0]',               \n","                                )                                 'reshape_2[0][0]',              \n","                                                                  'reshape[0][0]',                \n","                                                                  'reshape_1[0][0]']              \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 32, 32, 256)  452864      ['concatenate[0][0]']            \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, 32, 32, 128)  295040      ['conv2d_8[0][0]']               \n","                                                                                                  \n"," up_sampling2d (UpSampling2D)   (None, 64, 64, 128)  0           ['conv2d_9[0][0]']               \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, 64, 64, 64)   73792       ['up_sampling2d[0][0]']          \n","                                                                                                  \n"," up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 64  0          ['conv2d_10[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_11 (Conv2D)             (None, 128, 128, 32  18464       ['up_sampling2d_1[0][0]']        \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 128, 128, 16  4624        ['conv2d_11[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_13 (Conv2D)             (None, 128, 128, 2)  290         ['conv2d_12[0][0]']              \n","                                                                                                  \n"," up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 2)  0          ['conv2d_13[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 6,672,274\n","Trainable params: 6,672,274\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["LEARNING_RATE = 0.001\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n","                            loss='mean_absolute_error')\n","BATCH_SIZE = 32\n","EPOCHS = 50\n","\n","early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, \n","                           mode='auto', restore_best_weights=True)\n","\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n","                                filepath=CHECKPOINT,\n","                                save_weights_only=False,\n","                                monitor='val_loss',\n","                                mode='max',\n","                                save_best_only=False)\n","\n","model.summary()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19280818,"status":"ok","timestamp":1639074312895,"user":{"displayName":"Tuom Tat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06057362015267760681"},"user_tz":-420},"id":"w7zPk5NZVhpU","outputId":"fb2d9169-a9b9-496e-db12-353eea0125b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0205INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 1015s 5s/step - loss: 0.0205 - val_loss: 0.0281\n","Epoch 2/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0194INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 663s 3s/step - loss: 0.0194 - val_loss: 0.0278\n","Epoch 3/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0195INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 665s 3s/step - loss: 0.0195 - val_loss: 0.0278\n","Epoch 4/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0199INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 670s 3s/step - loss: 0.0199 - val_loss: 0.0281\n","Epoch 5/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0199INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 669s 3s/step - loss: 0.0199 - val_loss: 0.0290\n","Epoch 6/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0199INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 679s 3s/step - loss: 0.0199 - val_loss: 0.0278\n","Epoch 7/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0196INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 671s 3s/step - loss: 0.0196 - val_loss: 0.0285\n","Epoch 8/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0198INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 674s 3s/step - loss: 0.0198 - val_loss: 0.0276\n","Epoch 9/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0198INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 667s 3s/step - loss: 0.0198 - val_loss: 0.0278\n","Epoch 10/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0193INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 672s 3s/step - loss: 0.0193 - val_loss: 0.0274\n","Epoch 11/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0198INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 674s 3s/step - loss: 0.0198 - val_loss: 0.0279\n","Epoch 12/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0205INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 685s 3s/step - loss: 0.0205 - val_loss: 0.0279\n","Epoch 13/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0194INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 695s 3s/step - loss: 0.0194 - val_loss: 0.0283\n","Epoch 14/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0192INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 682s 3s/step - loss: 0.0192 - val_loss: 0.0290\n","Epoch 15/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0194INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 673s 3s/step - loss: 0.0194 - val_loss: 0.0277\n","Epoch 16/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0190INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 674s 3s/step - loss: 0.0190 - val_loss: 0.0285\n","Epoch 17/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0187INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 676s 3s/step - loss: 0.0187 - val_loss: 0.0293\n","Epoch 18/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0197INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 683s 3s/step - loss: 0.0197 - val_loss: 0.0273\n","Epoch 19/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0196INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 678s 3s/step - loss: 0.0196 - val_loss: 0.0278\n","Epoch 20/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0187INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 678s 3s/step - loss: 0.0187 - val_loss: 0.0282\n","Epoch 21/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0187INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 683s 3s/step - loss: 0.0187 - val_loss: 0.0275\n","Epoch 22/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0184INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 673s 3s/step - loss: 0.0184 - val_loss: 0.0283\n","Epoch 23/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0185INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 669s 3s/step - loss: 0.0185 - val_loss: 0.0277\n","Epoch 24/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0183INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 671s 3s/step - loss: 0.0183 - val_loss: 0.0277\n","Epoch 25/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0189INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 666s 3s/step - loss: 0.0189 - val_loss: 0.0280\n","Epoch 26/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0188INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 684s 3s/step - loss: 0.0188 - val_loss: 0.0278\n","Epoch 27/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0192INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 676s 3s/step - loss: 0.0192 - val_loss: 0.0282\n","Epoch 28/50\n","216/216 [==============================] - ETA: 0s - loss: 0.0186Restoring model weights from the end of the best epoch: 18.\n","INFO:tensorflow:Assets written to: model_resnet_color/assets\n","216/216 [==============================] - 677s 3s/step - loss: 0.0186 - val_loss: 0.0279\n","Epoch 00028: early stopping\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f66bafb3d10>"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(DataSequence(trainPath,BATCH_SIZE),\n","                        batch_size=BATCH_SIZE,\n","                        epochs=EPOCHS,\n","                        validation_data=DataSequence(validPath,BATCH_SIZE),\n","                        shuffle=True,\n","                        callbacks=[early_stop, model_checkpoint])"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNbJc3w6vxMLJ1z4dVEaVNh","collapsed_sections":[],"mount_file_id":"1hvkEt-6oWhMd9EHRKhg20pwempU7XyJe","name":"model_with_color.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
